#![cfg(not(target_arch = "wasm32"))]

use crate::{
    FinalizedEpoch, LightDataAvailabilityLayer, VerifiableEpoch,
    celestia::{
        DEFAULT_FETCH_MAX_RETRIES, DEFAULT_FETCH_TIMEOUT, DEVNET_SPECTER_OP_NAMESPACE_ID,
        DEVNET_SPECTER_SNARK_NAMESPACE_ID,
    },
};
use anyhow::{Context, Result, anyhow};
use async_trait::async_trait;
use celestia_types::{Blob, nmt::Namespace};
use prism_errors::{DataAvailabilityError, GeneralError};
use prism_events::{EventChannel, PrismEvent};
use prism_presets::PresetError;
use serde::{Deserialize, Serialize};
use std::{
    self,
    sync::{
        Arc,
        atomic::{AtomicU64, Ordering},
    },
};
use tokio::{sync::broadcast, time::Duration};
use tracing::{error, trace};

use crate::{DataAvailabilityLayer, celestia::CelestiaNetwork};
use celestia_rpc::{BlobClient, Client, HeaderClient, TxConfig};
use celestia_types::AppVersion;
use prism_common::transaction::Transaction;
use prism_serde::binary::ToBinary;
use tokio::task::spawn;
use tracing::{debug, warn};

use super::utils::create_namespace;

/// Configuration for Celestia full node data availability layer.
///
/// This configuration enables Prism full nodes to connect to the Celestia modular
/// data availability network using a full node participant.
///
/// # Celestia Integration
///
/// Prism uses Celestia to:
/// - Store batched transaction data with guaranteed availability
/// - Publish SNARK proofs for cryptographic verification
/// - Enable trust-minimized light client data retrieval
///
/// # Namespace Isolation
///
/// Prism uses Celestia namespaces to logically separate different types of data:
/// - **SNARK Namespace**: Contains zero-knowledge proofs of state transitions
/// - **Operation Namespace**: Contains raw transaction and operation data
///
/// This separation allows efficient filtering and reduces bandwidth requirements
/// for applications that only need specific data types.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CelestiaFullNodeDAConfig {
    /// WebSocket URL for connecting to the Celestia node.
    ///
    /// This should be a WebSocket endpoint of a Celestia full node or RPC service.
    /// Common formats:
    /// - `wss://rpc-mainnet.celestia.org/websocket` (Mainnet)
    /// - `wss://rpc-arabica.celestia.org/websocket` (Arabica testnet)
    /// - `ws://localhost:26657/websocket` (Local node)
    ///
    /// Ensure the endpoint supports the required RPC methods for data publication
    /// and retrieval. Use WSS (secure WebSocket) for production deployments.
    pub url: String,

    /// The Celestia network to connect to (Arabica, Mocha, or Mainnet).
    ///
    /// This must match the network that the RPC endpoint serves:
    /// - `Arabica`: Development testnet for latest features
    /// - `Mocha`: Stable testnet for production testing
    /// - `Mainnet`: Production network (handle with care)
    ///
    /// The network determines block time, gas costs, and available features.
    pub celestia_network: CelestiaNetwork,

    /// Hex-encoded namespace ID for SNARK proofs.
    ///
    /// All SNARK proofs generated by Prism provers will be published under
    /// this namespace. The namespace must be:
    /// - Unique to avoid conflicts with other applications
    /// - Consistent across all nodes in the Prism network
    pub snark_namespace_id: String,

    /// Hex-encoded namespace ID for operations/transactions.
    ///
    /// All transaction batches and operation data will be published under
    /// this namespace. Requirements are the same as `snark_namespace_id`
    /// but must be different to maintain logical separation.
    pub operation_namespace_id: String,

    /// Timeout duration for fetch operations from Celestia.
    ///
    /// Controls how long to wait for responses from the Celestia node before
    /// considering the request failed. Should account for:
    /// - Network latency to the Celestia RPC endpoint
    /// - Block processing time on Celestia
    /// - Load on the Celestia node and potential queueing delays
    ///
    /// Recommended: 30-120 seconds for production, 10-15 seconds for local testing.
    pub fetch_timeout: Duration,

    /// Maximum number of retries for failed fetch operations.
    ///
    /// When a fetch operation fails due to network issues or temporary node
    /// unavailability, this controls the retry behavior. Higher values provide
    /// better reliability but may increase latency during outages.
    ///
    /// Recommended: 3-5 retries for production, 1-2 for development.
    /// Set to 0 to disable retries entirely.
    pub fetch_max_retries: u64,
}

impl Default for CelestiaFullNodeDAConfig {
    fn default() -> Self {
        Self {
            url: "ws://localhost:26658".to_string(),
            celestia_network: CelestiaNetwork::Arabica,
            snark_namespace_id: "00000000000000de1008".to_string(),
            operation_namespace_id: "00000000000000de1009".to_string(),
            fetch_timeout: DEFAULT_FETCH_TIMEOUT,
            fetch_max_retries: DEFAULT_FETCH_MAX_RETRIES,
        }
    }
}

impl CelestiaFullNodeDAConfig {
    pub fn new_for_specter() -> std::result::Result<Self, PresetError> {
        let mut config = Self::default();
        config.apply_specter_preset()?;
        Ok(config)
    }

    pub fn apply_specter_preset(&mut self) -> std::result::Result<(), PresetError> {
        self.url = "ws://localhost:26658".to_string();
        self.celestia_network = CelestiaNetwork::Mocha;
        self.snark_namespace_id = DEVNET_SPECTER_SNARK_NAMESPACE_ID.to_string();
        self.operation_namespace_id = DEVNET_SPECTER_OP_NAMESPACE_ID.to_string();
        Ok(())
    }
}

pub struct CelestiaConnection {
    pub client: celestia_rpc::Client,
    pub snark_namespace: Namespace,
    pub operation_namespace: Namespace,
    pub fetch_timeout: Duration,
    pub fetch_max_retries: u64,

    height_update_tx: broadcast::Sender<u64>,
    sync_target: Arc<AtomicU64>,
    event_channel: Arc<EventChannel>,
}

impl CelestiaConnection {
    pub async fn new(config: &CelestiaFullNodeDAConfig, auth_token: Option<&str>) -> Result<Self> {
        let client = Client::new(&config.url, auth_token)
            .await
            .context("Failed to initialize websocket connection")
            .map_err(|e| DataAvailabilityError::NetworkError(e.to_string()))?;

        let snark_namespace = create_namespace(&config.snark_namespace_id).context(format!(
            "Failed to create snark namespace from: '{}'",
            &config.snark_namespace_id
        ))?;

        let operation_namespace =
            create_namespace(&config.operation_namespace_id).context(format!(
                "Failed to create operation namespace from: '{}'",
                &config.operation_namespace_id
            ))?;

        let (height_update_tx, _) = broadcast::channel(100);
        let event_channel = Arc::new(EventChannel::new());

        Ok(Self {
            client,
            snark_namespace,
            operation_namespace,
            height_update_tx,
            sync_target: Arc::new(AtomicU64::new(0)),
            event_channel,
            fetch_timeout: config.fetch_timeout,
            fetch_max_retries: config.fetch_max_retries,
        })
    }

    async fn try_fetch_blobs(&self, height: u64, namespace: Namespace) -> Result<Vec<Blob>> {
        for attempt in 0..self.fetch_max_retries {
            match tokio::time::timeout(
                self.fetch_timeout,
                BlobClient::blob_get_all(&self.client, height, &[namespace]),
            )
            .await
            {
                Ok(blob_result) => match blob_result {
                    Ok(maybe_blobs) => match maybe_blobs {
                        Some(blobs) => {
                            return Ok(blobs);
                        }
                        None => return Ok(vec![]),
                    },
                    Err(err) => {
                        if err.to_string().contains("blob: not found") {
                            return Ok(vec![]);
                        }
                        warn!(
                            "failed to fetch data on attempt {} with error: {}.",
                            attempt + 1,
                            err
                        );
                        if attempt == self.fetch_max_retries - 1 {
                            return Err(anyhow!(DataAvailabilityError::DataRetrievalError(
                                height,
                                format!("getting epoch from da layer: {}", err)
                            )));
                        }
                    }
                },
                Err(timeout_err) => {
                    warn!(
                        "timeout on attempt {} with error: {}.",
                        attempt + 1,
                        timeout_err
                    );
                }
            }
        }
        Err(anyhow!(DataAvailabilityError::DataRetrievalError(
            height,
            "Max retry count exceeded".to_string()
        )))
    }
}

#[async_trait]
impl LightDataAvailabilityLayer for CelestiaConnection {
    async fn get_finalized_epochs(&self, height: u64) -> Result<Vec<VerifiableEpoch>> {
        trace!("searching for epoch on da layer at height {}", height);
        let valid_epochs: Vec<VerifiableEpoch> = self
            .try_fetch_blobs(height, self.snark_namespace)
            .await?
            .into_iter()
            .filter_map(|blob| {
                match FinalizedEpoch::try_from(&blob) {
                    Ok(epoch) => Some(Box::new(epoch) as VerifiableEpoch),
                    Err(e) => {
                        warn!(
                            "Ignoring blob: marshalling blob from height {} to epoch json failed with error {}: {:?}",
                            height, e, &blob
                        );
                        None
                    }
                }
            })
            .collect();
        Ok(valid_epochs)
    }

    fn event_channel(&self) -> Arc<EventChannel> {
        self.event_channel.clone()
    }
}

#[async_trait]
impl DataAvailabilityLayer for CelestiaConnection {
    async fn start(&self) -> Result<()> {
        let mut header_sub = HeaderClient::header_subscribe(&self.client)
            .await
            .context("Failed to subscribe to headers from DA layer")?;

        let sync_target = self.sync_target.clone();
        let height_update_tx = self.height_update_tx.clone();
        let event_publisher = self.event_channel.publisher();

        spawn(async move {
            while let Some(extended_header_result) = header_sub.next().await {
                match extended_header_result {
                    Ok(extended_header) => {
                        let height = extended_header.header.height.value();
                        sync_target.store(height, Ordering::Relaxed);
                        // todo: correct error handling
                        let _ = height_update_tx.send(height);
                        trace!("updated sync target for height {}", height);

                        event_publisher.send(PrismEvent::UpdateDAHeight { height });
                    }
                    Err(e) => {
                        error!("Error retrieving header from DA layer: {}", e);
                    }
                }
            }
        });
        Ok(())
    }

    fn subscribe_to_heights(&self) -> broadcast::Receiver<u64> {
        self.height_update_tx.subscribe()
    }

    async fn get_latest_height(&self) -> Result<u64> {
        Ok(self.sync_target.load(Ordering::Relaxed))
    }

    async fn initialize_sync_target(&self) -> Result<u64> {
        let height = HeaderClient::header_network_head(&self.client)
            .await
            .context("Failed to get network head from DA layer")
            .map(|extended_header| extended_header.header.height.value())?;

        self.sync_target.store(height, Ordering::Relaxed);
        Ok(height)
    }

    async fn submit_finalized_epoch(&self, epoch: FinalizedEpoch) -> Result<u64> {
        let data = epoch.encode_to_bytes().map_err(|e| {
            DataAvailabilityError::GeneralError(GeneralError::ParsingError(format!(
                "serializing epoch {}: {}",
                epoch.height, e
            )))
        })?;

        debug!(
            "posting {}th epoch to da layer ({} bytes)",
            epoch.height,
            data.len()
        );

        debug!("epoch: {:?}", epoch);

        let blob = Blob::new(self.snark_namespace, data, AppVersion::V3).map_err(|e| {
            DataAvailabilityError::GeneralError(GeneralError::BlobCreationError(e.to_string()))
        })?;

        self.client
            .blob_submit(&[blob], TxConfig::default())
            .await
            .map_err(|e| anyhow!(DataAvailabilityError::SubmissionError(e.to_string())))
    }

    async fn get_transactions(&self, height: u64) -> Result<Vec<Transaction>> {
        trace!(
            "searching for transactions on da layer at height {}",
            height
        );

        let transactions = self
            .try_fetch_blobs(height, self.operation_namespace)
            .await?
            .iter()
            .filter_map(|blob| match Transaction::try_from(blob) {
                Ok(transaction) => Some(transaction),
                Err(e) => {
                    warn!(
                        "Failed to parse blob from height {} to transaction: {:?}",
                        height, e
                    );
                    None
                }
            })
            .collect();
        Ok(transactions)
    }

    async fn submit_transactions(&self, transactions: Vec<Transaction>) -> Result<u64> {
        debug!("posting {} transactions to DA layer", transactions.len());
        let blobs: Result<Vec<Blob>, _> = transactions
            .iter()
            .map(|transaction| {
                let data = transaction
                    .encode_to_bytes()
                    .context(format!("Failed to serialize transaction {:?}", transaction))
                    .map_err(|e| {
                        DataAvailabilityError::GeneralError(GeneralError::ParsingError(
                            e.to_string(),
                        ))
                    })?;

                Blob::new(self.operation_namespace, data, AppVersion::V3)
                    .context(format!(
                        "Failed to create blob for transaction {:?}",
                        transaction
                    ))
                    .map_err(|e| {
                        DataAvailabilityError::GeneralError(GeneralError::BlobCreationError(
                            e.to_string(),
                        ))
                    })
            })
            .collect();

        let blobs = blobs?;

        for (i, blob) in blobs.iter().enumerate() {
            trace!("blob {}: {:?}", i, blob);
        }

        self.client
            .blob_submit(&blobs, TxConfig::default())
            .await
            .map_err(|e| anyhow!(DataAvailabilityError::SubmissionError(e.to_string())))
    }
}
